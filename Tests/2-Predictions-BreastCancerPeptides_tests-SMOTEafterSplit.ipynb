{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of Breast Cancer peptides with the best MLP classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE after data split (in each CV fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_auc_score,f1_score, recall_score, precision_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.feature_selection import RFECV, VarianceThreshold, SelectKBest, chi2\n",
    "from sklearn.feature_selection import SelectFromModel, SelectPercentile, f_classif\n",
    "\n",
    "import seaborn as sns; sns.set() # data visualization library \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from myFunctions import *\n",
    "\n",
    "# define output variables\n",
    "outVar = 'Class'\n",
    "\n",
    "# define list of folds\n",
    "nfold = 3\n",
    "\n",
    "# define a label for output files\n",
    "label = 'Outer'\n",
    "\n",
    "# seed obtained with getResultsMultiSeeds.ipynb\n",
    "# the seed with the mean AUROC of 3-fold CV closest to the general average of all the seeds (1-50)\n",
    "seed = 74 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual ML and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Read dataset ./best_classifier/Mix_BreastCancer.csv\n",
      "8744\n"
     ]
    }
   ],
   "source": [
    "# read dataset for the best model (it will generate: Mix-Best300)\n",
    "sFile = './best_classifier/Mix_BreastCancer.csv'\n",
    "\n",
    "print('\\n-> Read dataset', sFile)\n",
    "df = pd.read_csv(sFile)\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Modify dataset\n",
      "Done!\n",
      "8742\n",
      "\n",
      "-> Drop ProtID column\n",
      "Done!\n",
      "8741\n",
      "\n",
      "-> Checking dataset\n",
      "\n",
      "Data points = 376\n",
      "\n",
      "Columns (output + features)= 8741\n",
      "\n",
      "Data types = [dtype('float64') dtype('int64')]\n",
      "\n",
      "\n",
      "Column Names:\n",
      " Index(['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', 'I',\n",
      "       ...\n",
      "       'DAYM780201.lag22', 'DAYM780201.lag23', 'DAYM780201.lag24',\n",
      "       'DAYM780201.lag25', 'DAYM780201.lag26', 'DAYM780201.lag27',\n",
      "       'DAYM780201.lag28', 'DAYM780201.lag29', 'DAYM780201.lag30', 'Class'],\n",
      "      dtype='object', length=8741)\n",
      "\n",
      "Categorical features: []\n",
      "\n",
      "Columns with NaN:  0  /  8741\n",
      "\n",
      "No of data points with NaN: 0  /  376\n",
      "Done!\n",
      "\n",
      "-> Dataset preprocessing\n",
      "Inicial shape: (376, 8741)\n",
      "Data points = 376\n",
      "Columns (output + features)= 8741\n",
      "Data types = [dtype('float64') dtype('int64')]\n",
      "\n",
      "\n",
      "Column Names:\n",
      " Index(['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', 'I',\n",
      "       ...\n",
      "       'DAYM780201.lag22', 'DAYM780201.lag23', 'DAYM780201.lag24',\n",
      "       'DAYM780201.lag25', 'DAYM780201.lag26', 'DAYM780201.lag27',\n",
      "       'DAYM780201.lag28', 'DAYM780201.lag29', 'DAYM780201.lag30', 'Class'],\n",
      "      dtype='object', length=8741)\n",
      "Categorical features: []\n",
      "Columns with NaN:  0  /  8741\n",
      "No of data points with NaN: 0  /  376\n",
      "* Remove duplicates\n",
      "Final shape: (376, 8741)\n",
      "Done!\n",
      "8741\n",
      "\n",
      "-> Get X & Y data, Features list\n",
      "Shape (376, 8741)\n",
      "Shape X data: (376, 8740)\n",
      "Shape Y data: (376,)\n",
      "Done!\n",
      "\n",
      "-> Remove zero variance features\n",
      "Removed features: ['IWW', 'CNW', 'WHH', 'WCC', 'WWV', 'WCH', 'NWH', 'QWW', 'WGC', 'WHD', 'WWM', 'WQM', 'IHW', 'WWH', 'MYM', 'AWW', 'MWW', 'HWF', 'YWW', 'CMH', 'YCW', 'WMF', 'WMW', 'HWW', 'VMW', 'MWH', 'WCK', 'WWC', 'CMW', 'WIW', 'MWP', 'PWY']\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Clean columns (remove all extra columns but keep ProtID!)\n",
    "df = ClearDatasets(df)\n",
    "print(len(df.columns))\n",
    "\n",
    "# drop ProtID to have only descriptors + Class (raw dataset)\n",
    "print('\\n-> Drop ProtID column')\n",
    "df= df.drop(['ProtID'],axis = 1)\n",
    "print('Done!')\n",
    "print(len(df.columns))\n",
    "\n",
    "# Check dataset\n",
    "DataCheckings(df)\n",
    "\n",
    "# Dataset preprocessing\n",
    "df = DataPreprocessing(df)\n",
    "print(len(df.columns))\n",
    "\n",
    "# Remove zero variance columns\n",
    "df = Remove0VarCols(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Save raw dataset: ./best_classifier/Mix_BreastCancer.ds_raw.csv\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Save initial ds\n",
    "rawFile = sFile[:-4]+'.ds_raw.csv'\n",
    "print('\\n-> Save raw dataset:',rawFile)\n",
    "df.to_csv(rawFile, index=False)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Read dataset ./best_classifier/Screening_3_RBPs.csv\n",
      "8741\n"
     ]
    }
   ],
   "source": [
    "# read the prediction file with the same descriptors (all from Mix)\n",
    "# read dataset for the best model (it will generate: Mix-Best300)\n",
    "sFilep = './best_classifier/Screening_3_RBPs.csv' \n",
    "# Screening_1_Metastasis.csv, Screening_2_Cancer_Immunotherapy_Genes.csv, Screening_3_RBPs.csv\n",
    "\n",
    "print('\\n-> Read dataset', sFilep)\n",
    "dfp = pd.read_csv(sFilep)\n",
    "print(len(dfp.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Checking dataset\n",
      "\n",
      "Data points = 1369\n",
      "\n",
      "Columns (output + features)= 8741\n",
      "\n",
      "Data types = [dtype('float64') dtype('int64')]\n",
      "\n",
      "\n",
      "Column Names:\n",
      " Index(['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', 'I',\n",
      "       ...\n",
      "       'Pc2.Hydrophilicity.26', 'Pc2.Hydrophobicity.27',\n",
      "       'Pc2.Hydrophilicity.27', 'Pc2.Hydrophobicity.28',\n",
      "       'Pc2.Hydrophilicity.28', 'Pc2.Hydrophobicity.29',\n",
      "       'Pc2.Hydrophilicity.29', 'Pc2.Hydrophobicity.30',\n",
      "       'Pc2.Hydrophilicity.30', 'Class'],\n",
      "      dtype='object', length=8741)\n",
      "\n",
      "Categorical features: []\n",
      "\n",
      "Columns with NaN:  0  /  8741\n",
      "\n",
      "No of data points with NaN: 0  /  1369\n",
      "Done!\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing of prediction file\n",
    "# Clean columns (remove all extra columns but keep ProtID!)\n",
    "#df = ClearDatasets(df)\n",
    "#print(len(df.columns))\n",
    "\n",
    "# drop ProtID to have only descriptors + Class (raw dataset)\n",
    "#print('\\n-> Drop ProtID column')\n",
    "#df= df.drop(['ProtID'],axis = 1)\n",
    "#print('Done!')\n",
    "#print(len(df.columns))\n",
    "\n",
    "# Check dataset\n",
    "print(DataCheckings(dfp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1369, 8709)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the same features as the dataset\n",
    "dfp = dfp[list(df.columns)]\n",
    "dfp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Get X & Y data, Features list\n",
      "Shape (376, 8709)\n",
      "Shape X data: (376, 8708)\n",
      "Shape Y data: (376,)\n",
      "Done!\n",
      "\n",
      "-> Get X & Y data, Features list\n",
      "Shape (1369, 8709)\n",
      "Shape X data: (1369, 8708)\n",
      "Shape Y data: (1369,)\n",
      "Done!\n",
      "* Save scaler: ./best_classifier/Mix_BreastCancer.scaler_Std.pkl\n",
      "* Save scaled dataset: ./best_classifier/Mix_BreastCancer.ds_std.csv\n",
      "* Save scaled dataset: ./best_classifier/Screening_3_RBPs.ds_std.csv\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Scale raw dataframe\n",
    "# scale dataframe, save scaled file, save scaler\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(df)# out var = Class\n",
    "Xdatap, Ydatap, Featuresp = getDataFromDataFrame(dfp)# prediction data\n",
    "\n",
    "# Normalize dataset & prediction set\n",
    "scaler = MinMaxScaler()\n",
    "Xdata = scaler.fit_transform(Xdata)\n",
    "Xdatap = scaler.transform(Xdatap) # scaler prediction data with the same scaler\n",
    "\n",
    "df = pd.DataFrame(Xdata,columns=Features)\n",
    "df['Class'] = Ydata # add class column\n",
    "\n",
    "dfp = pd.DataFrame(Xdatap,columns=Featuresp)\n",
    "dfp['Class'] = Ydatap # add class column\n",
    "\n",
    "scalerFile = sFile[:-4]+'.scaler_Std.pkl'\n",
    "print('* Save scaler:', scalerFile)\n",
    "joblib.dump(scaler, scalerFile) \n",
    "\n",
    "# Save initial ds\n",
    "scaledFile = sFile[:-4]+'.ds_std.csv'\n",
    "print('* Save scaled dataset:', scaledFile)\n",
    "df.to_csv(scaledFile, index=False)\n",
    "\n",
    "# Save initial ds for predictions\n",
    "scaledFilep = sFilep[:-4]+'.ds_std.csv'\n",
    "print('* Save scaled dataset:', scaledFilep)\n",
    "dfp.to_csv(scaledFilep, index=False)\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Get X & Y data, Features list\n",
      "Shape (376, 8709)\n",
      "Shape X data: (376, 8708)\n",
      "Shape Y data: (376,)\n",
      "Done!\n",
      "\n",
      "-> Univariate Feature selection\n",
      "* Save selector: ./best_classifier/Mix_BreastCancer.featSelector_Univariate300.pkl\n",
      "Final columns: ['MN', 'LG', 'QI', 'NK', 'EM', 'QM', 'MM', 'EY', 'FAA', 'FNA', 'PNA', 'MDA', 'YHA', 'YKA', 'WFA', 'GPA', 'NTA', 'EYA', 'PAR', 'QDR', 'KER', 'SQR', 'QGR', 'LLR', 'HKR', 'TKR', 'TMR', 'YMR', 'MFR', 'EAN', 'HAN', 'MRN', 'SNN', 'EDN', 'QCN', 'QQN', 'GQN', 'PGN', 'IHN', 'NKN', 'HKN', 'LKN', 'AMN', 'TMN', 'VMN', 'MPN', 'PSN', 'YTN', 'KWN', 'PWN', 'EYN', 'PYN', 'LVN', 'PVN', 'SVN', 'VAD', 'HRD', 'IND', 'PDD', 'IQD', 'NHD', 'YHD', 'NID', 'HFD', 'ITD', 'RYD', 'IYD', 'QRC', 'DNC', 'SNC', 'MDC', 'AQC', 'CGC', 'MGC', 'VHC', 'CKC', 'IKC', 'SKC', 'MMC', 'PFC', 'MPC', 'MVC', 'FVC', 'FDE', 'YDE', 'SQE', 'TQE', 'RHE', 'MHE', 'HIE', 'FKE', 'EME', 'QME', 'LME', 'MME', 'VME', 'SFE', 'DAQ', 'TNQ', 'IDQ', 'DCQ', 'KCQ', 'GLQ', 'FKQ', 'AMQ', 'CMQ', 'VPQ', 'PSQ', 'IWQ', 'YWQ', 'CYQ', 'IAG', 'PAG', 'MNG', 'VGG', 'ALG', 'FLG', 'VLG', 'WMG', 'DFG', 'PFG', 'CTG', 'FWG', 'PWG', 'TVG', 'FAH', 'INH', 'PCH', 'VQH', 'CGH', 'CKH', 'IKH', 'SKH', 'MFH', 'WFH', 'HTH', 'RWH', 'FWH', 'GYH', 'RVH', 'KRI', 'MRI', 'AQI', 'LQI', 'NHI', 'NII', 'QII', 'CKI', 'YKI', 'IPI', 'WSI', 'EYI', 'LYI', 'MVI', 'RDL', 'TCL', 'CQL', 'HQL', 'MQL', 'GGL', 'LGL', 'HLL', 'HML', 'QWL', 'EYL', 'GVL', 'IVL', 'HAK', 'KNK', 'VNK', 'SCK', 'TQK', 'KHK', 'VHK', 'QIK', 'PIK', 'DLK', 'MMK', 'EPK', 'HTK', 'CWK', 'DVK', 'WAM', 'HRM', 'QNM', 'PNM', 'VDM', 'AEM', 'EEM', 'QQM', 'QGM', 'RIM', 'CIM', 'QLM', 'ILM', 'HKM', 'AMM', 'NMM', 'CFM', 'NTM', 'TTM', 'VTM', 'CWM', 'EWM', 'FYM', 'TAF', 'YCF', 'AEF', 'RQF', 'VGF', 'PKF', 'AMF', 'YFF', 'HTF', 'GYF', 'DAP', 'MNP', 'SNP', 'RGP', 'QGP', 'PGP', 'VGP', 'WLP', 'DKP', 'IKP', 'LKP', 'CMP', 'IFP', 'QTP', 'KTP', 'IWP', 'MNS', 'KQS', 'WGS', 'CHS', 'MMS', 'TMS', 'LNT', 'DCT', 'CQT', 'PQT', 'FHT', 'IIT', 'PIT', 'GLT', 'MLT', 'VLT', 'MKT', 'WKT', 'TMT', 'IFT', 'MPT', 'EWT', 'QWT', 'KWT', 'EYT', 'GAW', 'LNW', 'ADW', 'HCW', 'NEW', 'EEW', 'YEW', 'DQW', 'QHW', 'GIW', 'HIW', 'LLW', 'IKW', 'VKW', 'FPW', 'RTW', 'VTW', 'WYW', 'DVW', 'SVW', 'NDY', 'PDY', 'ECY', 'GCY', 'MEY', 'TEY', 'EIY', 'KIY', 'PIY', 'EMY', 'MPY', 'TPY', 'HWY', 'KNV', 'VNV', 'NDV', 'KCV', 'GHV', 'GLV', 'MMV', 'VFV', 'IYV', 'Pc1.N', 'Pc1.M', 'Class']\n",
      "* Save selected features dataset: ./best_classifier/Mix_BreastCancer.ds_sel.csv\n",
      "* Save selected features dataset: ./best_classifier/Screening_3_RBPs.ds_sel.csv\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "nFeats = 300\n",
    "\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(df)# out var = Class\n",
    "\n",
    "print('\\n-> Univariate Feature selection')\n",
    "selector= SelectKBest(chi2, k=nFeats)\n",
    "Xdata = selector.fit_transform(Xdata, Ydata)\n",
    "    \n",
    "selectorFile = sFile[:-4]+'.featSelector_Univariate'+str(nFeats)+'.pkl'\n",
    "print('* Save selector:', selectorFile)\n",
    "joblib.dump(selector, selectorFile) \n",
    "    \n",
    "# Selected features\n",
    "SelFeatures = []\n",
    "for i in selector.get_support(indices=True):\n",
    "    SelFeatures.append(Features[i])\n",
    "        \n",
    "# create the resulted dataframe\n",
    "df = pd.DataFrame(Xdata,columns=SelFeatures)\n",
    "df['Class'] = Ydata # add class column\n",
    "print('Final columns:', list(df.columns))\n",
    "    \n",
    "# Save selected feature ds\n",
    "selectFile = sFile[:-4]+'.ds_sel.csv'\n",
    "print('* Save selected features dataset:', selectFile)\n",
    "df.to_csv(selectFile, index=False)\n",
    "\n",
    "# create the resulted dataframe for predictions\n",
    "dfp = dfp[list(df.columns)]\n",
    "    \n",
    "# Save selected feature ds\n",
    "selectFilep = sFilep[:-4]+'.ds_sel.csv'\n",
    "print('* Save selected features dataset:', selectFilep)\n",
    "dfp.to_csv(selectFilep, index=False)\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376, 301)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1369, 301)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing dataframe using SMOTE\n",
    "# df = SMOTEdf(df,sFile,seed)\n",
    "# df = UndersampleDF(df, sFile, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(376, 301)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Get X & Y data, Features list\n",
      "Shape (376, 301)\n",
      "Shape X data: (376, 300)\n",
      "Shape Y data: (376,)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# get ds for ML\n",
    "Xdata, Ydata, Features = getDataFromDataFrame(df)# out var = Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights =  {0: 0.8068669527896996, 1: 1.3146853146853146}\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights\n",
    "class_weights = set_weights(Ydata)\n",
    "print(\"Class weights = \", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv = StratifiedKFold(n_splits=3,shuffle=True,random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 1\n",
      "AUROC= 0.9682774490466799 ACC= 0.9102564102564102 0.008986107508341471 mins\n",
      "Fold = 2\n",
      "AUROC= 0.9811097992916173 ACC= 0.9155844155844156 0.006299865245819092 mins\n",
      "Fold = 3\n",
      "AUROC= 0.9534845496383958 ACC= 0.8653846153846154 0.005884281794230143 mins\n"
     ]
    }
   ],
   "source": [
    "ifold = 0\n",
    "ACCs  =[]\n",
    "AUROCs=[]\n",
    "models =[]\n",
    "SelectedFeatures =[]\n",
    "\n",
    "for train_index, test_index in outer_cv.split(Xdata, Ydata):\n",
    "    ifold +=1\n",
    "    \n",
    "    print(\"Fold =\",ifold)\n",
    "    start = time.time()\n",
    "    \n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = Xdata[train_index], Xdata[test_index]\n",
    "    y_train, y_test = Ydata[train_index], Ydata[test_index]\n",
    "    \n",
    "    # Apply SMOTE to the training data\n",
    "    smote_tr = SMOTE(random_state=seed)\n",
    "    X_train_resampled, y_train_resampled = smote_tr.fit_resample(X_train, y_train)\n",
    "\n",
    "    #scaler.transform(X_test)\n",
    "    clf = MLPClassifier(hidden_layer_sizes= (20),\n",
    "                        random_state = seed,\n",
    "                        max_iter=50000, shuffle=False)\n",
    "    clf.fit(X_train_resampled, y_train_resampled)\n",
    "    \n",
    "    joblib.dump(clf, './best_classifier/MLP_model_smote'+str(ifold)+'.pkl', compress = 1)\n",
    "    models.append(clf)\n",
    "    \n",
    "    # SMOTE the testing data too!!!!!!\n",
    "    smote_ts = SMOTE(random_state=seed)\n",
    "    X_test_resampled, y_test_resampled = smote_ts.fit_resample(X_test, y_test)\n",
    "    \n",
    "    # Use decision_function instead of predict_proba\n",
    "    if hasattr(clf, 'decision_function'):\n",
    "        y_scores = clf.decision_function(X_test_resampled)\n",
    "    elif hasattr(clf, 'predict_proba'):\n",
    "        y_scores = clf.predict_proba(X_test_resampled)[:, 1]\n",
    "    else:\n",
    "        raise AttributeError(\"Classifier has no decision_function or predict_proba method\")\n",
    "    \n",
    "    # Calculate ROC AUC score\n",
    "    AUROC = roc_auc_score(y_test_resampled, y_scores)\n",
    "        \n",
    "    #y_pred = clf.predict_proba(X_test)\n",
    "    #AUROC = roc_auc_score(y_test, y_pred[:, 1])\n",
    "    AUROCs.append(AUROC)\n",
    "    \n",
    "    ACC = clf.score(X_test_resampled,y_test_resampled)\n",
    "    ACCs.append(ACC)\n",
    "   \n",
    "    print(\"AUROC=\",AUROC,\"ACC=\",ACC, (time.time() - start)/60,\"mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9676239326588977 0.011287424192511159\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(AUROCs),np.std(AUROCs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8970751470751471 0.022513910652679565\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(ACCs),np.std(ACCs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1903, 301)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-> Get X & Y data, Features list\n",
      "Shape (1369, 301)\n",
      "Shape X data: (1369, 300)\n",
      "Shape Y data: (1369,)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# get ds for ML\n",
    "Xdatap, Ydatap, Featuresp = getDataFromDataFrame(dfp)# out var = Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1369, 300)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xdatap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved model 2 from disk: AUROC= 0.9747340425531915 ACC= 0.9157894736842105 (close to general mean AUROC for 50 seeds)\n",
    "clf = joblib.load('./best_classifier/MLP_model_smote'+str(2)+'.pkl')\n",
    "\n",
    "# predictions with the model\n",
    "Ydatap = clf.predict(Xdatap)\n",
    "        \n",
    "# add probabilities (n_samples X n_classes; class 0, class 1)\n",
    "Ydatapprob = clf.predict_proba(Xdatap)\n",
    "        \n",
    "# save predictions for list 1\n",
    "dffp = pd.DataFrame(Xdatap,columns=Featuresp)\n",
    "dffp['Class'] = Ydatap\n",
    "dffp['Prob0'] = Ydatapprob[:,0]\n",
    "dffp['Prob1'] = Ydatapprob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MN</th>\n",
       "      <th>LG</th>\n",
       "      <th>QI</th>\n",
       "      <th>NK</th>\n",
       "      <th>EM</th>\n",
       "      <th>QM</th>\n",
       "      <th>MM</th>\n",
       "      <th>EY</th>\n",
       "      <th>FAA</th>\n",
       "      <th>FNA</th>\n",
       "      <th>...</th>\n",
       "      <th>GHV</th>\n",
       "      <th>GLV</th>\n",
       "      <th>MMV</th>\n",
       "      <th>VFV</th>\n",
       "      <th>IYV</th>\n",
       "      <th>Pc1.N</th>\n",
       "      <th>Pc1.M</th>\n",
       "      <th>Class</th>\n",
       "      <th>Prob0</th>\n",
       "      <th>Prob1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.218033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241530</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305738</td>\n",
       "      <td>0.345902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532895</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.976974</td>\n",
       "      <td>0.037229</td>\n",
       "      <td>0.035432</td>\n",
       "      <td>0</td>\n",
       "      <td>0.996625</td>\n",
       "      <td>0.003375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.258755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014129</td>\n",
       "      <td>0.014227</td>\n",
       "      <td>1</td>\n",
       "      <td>0.203024</td>\n",
       "      <td>0.796976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448454</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022057</td>\n",
       "      <td>0.034894</td>\n",
       "      <td>1</td>\n",
       "      <td>0.004913</td>\n",
       "      <td>0.995087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277828</td>\n",
       "      <td>0.067214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085082</td>\n",
       "      <td>0.770073</td>\n",
       "      <td>0.070712</td>\n",
       "      <td>0.171533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.307763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225567</td>\n",
       "      <td>0.371813</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020595</td>\n",
       "      <td>0.979405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.096377</td>\n",
       "      <td>0.567391</td>\n",
       "      <td>0.213527</td>\n",
       "      <td>0.342029</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181643</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136595</td>\n",
       "      <td>0.146389</td>\n",
       "      <td>0</td>\n",
       "      <td>0.902327</td>\n",
       "      <td>0.097673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152364</td>\n",
       "      <td>0.129013</td>\n",
       "      <td>0.551080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109749</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131570</td>\n",
       "      <td>0.076788</td>\n",
       "      <td>0</td>\n",
       "      <td>0.908360</td>\n",
       "      <td>0.091640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>0.154651</td>\n",
       "      <td>0.202326</td>\n",
       "      <td>0.171318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180233</td>\n",
       "      <td>0.145736</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088178</td>\n",
       "      <td>0.096063</td>\n",
       "      <td>1</td>\n",
       "      <td>0.054835</td>\n",
       "      <td>0.945165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1366</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202797</td>\n",
       "      <td>0.171717</td>\n",
       "      <td>0.183372</td>\n",
       "      <td>0.217366</td>\n",
       "      <td>0.245921</td>\n",
       "      <td>0.090326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103424</td>\n",
       "      <td>0.182230</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037346</td>\n",
       "      <td>0.962654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273585</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023453</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0</td>\n",
       "      <td>0.891812</td>\n",
       "      <td>0.108188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144638</td>\n",
       "      <td>0.183707</td>\n",
       "      <td>0.065392</td>\n",
       "      <td>0.077515</td>\n",
       "      <td>0.087697</td>\n",
       "      <td>0.322111</td>\n",
       "      <td>0.260460</td>\n",
       "      <td>0.248752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170554</td>\n",
       "      <td>0.205112</td>\n",
       "      <td>1</td>\n",
       "      <td>0.013811</td>\n",
       "      <td>0.986189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1369 rows Ã— 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            MN        LG        QI        NK        EM        QM        MM  \\\n",
       "0     0.218033  0.000000  0.241530  0.000000  0.305738  0.345902  0.000000   \n",
       "1     0.258755  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2     0.000000  0.448454  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3     0.000000  0.277828  0.067214  0.000000  0.085082  0.770073  0.070712   \n",
       "4     0.096377  0.567391  0.213527  0.342029  0.000000  0.152899  0.000000   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1364  0.000000  0.152364  0.129013  0.551080  0.000000  0.000000  0.000000   \n",
       "1365  0.154651  0.202326  0.171318  0.000000  0.216860  0.000000  0.180233   \n",
       "1366  0.000000  0.202797  0.171717  0.183372  0.217366  0.245921  0.090326   \n",
       "1367  0.000000  0.273585  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1368  0.000000  0.144638  0.183707  0.065392  0.077515  0.087697  0.322111   \n",
       "\n",
       "            EY       FAA  FNA  ...  GHV       GLV       MMV  VFV       IYV  \\\n",
       "0     0.000000  0.000000  0.0  ...  0.0  0.532895  0.000000  0.0  0.976974   \n",
       "1     0.000000  0.000000  0.0  ...  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "2     0.000000  0.000000  0.0  ...  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "3     0.171533  0.000000  0.0  ...  0.0  0.000000  0.307763  0.0  0.000000   \n",
       "4     0.181643  0.433962  0.0  ...  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "...        ...       ...  ...  ...  ...       ...       ...  ...       ...   \n",
       "1364  0.109749  0.000000  0.0  ...  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "1365  0.145736  0.000000  0.0  ...  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "1366  0.000000  0.000000  0.0  ...  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "1367  0.000000  0.000000  0.0  ...  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "1368  0.260460  0.248752  0.0  ...  0.0  0.000000  0.000000  0.0  0.000000   \n",
       "\n",
       "         Pc1.N     Pc1.M  Class     Prob0     Prob1  \n",
       "0     0.037229  0.035432      0  0.996625  0.003375  \n",
       "1     0.014129  0.014227      1  0.203024  0.796976  \n",
       "2     0.022057  0.034894      1  0.004913  0.995087  \n",
       "3     0.225567  0.371813      1  0.020595  0.979405  \n",
       "4     0.136595  0.146389      0  0.902327  0.097673  \n",
       "...        ...       ...    ...       ...       ...  \n",
       "1364  0.131570  0.076788      0  0.908360  0.091640  \n",
       "1365  0.088178  0.096063      1  0.054835  0.945165  \n",
       "1366  0.103424  0.182230      1  0.037346  0.962654  \n",
       "1367  0.023453  0.001518      0  0.891812  0.108188  \n",
       "1368  0.170554  0.205112      1  0.013811  0.986189  \n",
       "\n",
       "[1369 rows x 303 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dffp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with protein information from other file\n",
    "# AC.Screening_1_Metastasis.csv, AC.Screening_2_Cancer_Immunotherapy_Genes.csv, AC.Screening_3_RBPs.csv\n",
    "result = pd.concat([dffp, pd.read_csv('./best_classifier/AC.Screening_3_RBPs.csv')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat new order of columns in final results\n",
    "newHeader=['Class','Prob1','Prob0','V1','V2']\n",
    "result = result[newHeader]\n",
    "result = result.sort_values(by=['Prob1'], ascending=False)\n",
    "result.to_csv(sFilep[:-4]+'_predictions_smote.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
